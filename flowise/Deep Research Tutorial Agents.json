{
  "nodes": [
    {
      "id": "startAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": -179.5,
        "y": 41.5
      },
      "data": {
        "id": "startAgentflow_0",
        "label": "Start",
        "version": 1.1,
        "name": "startAgentflow",
        "type": "Start",
        "color": "#7EE787",
        "hideInput": true,
        "baseClasses": [
          "Start"
        ],
        "category": "Agent Flows",
        "description": "Starting point of the agentflow",
        "inputParams": [
          {
            "label": "Input Type",
            "name": "startInputType",
            "type": "options",
            "options": [
              {
                "label": "Chat Input",
                "name": "chatInput",
                "description": "Start the conversation with chat input"
              },
              {
                "label": "Form Input",
                "name": "formInput",
                "description": "Start the workflow with form inputs"
              }
            ],
            "default": "chatInput",
            "id": "startAgentflow_0-input-startInputType-options",
            "display": true
          },
          {
            "label": "Form Title",
            "name": "formTitle",
            "type": "string",
            "placeholder": "Please Fill Out The Form",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formTitle-string",
            "display": true
          },
          {
            "label": "Form Description",
            "name": "formDescription",
            "type": "string",
            "placeholder": "Complete all fields below to continue",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formDescription-string",
            "display": true
          },
          {
            "label": "Form Input Types",
            "name": "formInputTypes",
            "description": "Specify the type of form input",
            "type": "array",
            "show": {
              "startInputType": "formInput"
            },
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Options",
                    "name": "options"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Label",
                "name": "label",
                "type": "string",
                "placeholder": "Label for the input"
              },
              {
                "label": "Variable Name",
                "name": "name",
                "type": "string",
                "placeholder": "Variable name for the input (must be camel case)",
                "description": "Variable name must be camel case. For example: firstName, lastName, etc."
              },
              {
                "label": "Add Options",
                "name": "addOptions",
                "type": "array",
                "show": {
                  "formInputTypes[$index].type": "options"
                },
                "array": [
                  {
                    "label": "Option",
                    "name": "option",
                    "type": "string"
                  }
                ]
              }
            ],
            "id": "startAgentflow_0-input-formInputTypes-array",
            "display": true
          },
          {
            "label": "Ephemeral Memory",
            "name": "startEphemeralMemory",
            "type": "boolean",
            "description": "Start fresh for every execution without past chat history",
            "optional": true,
            "id": "startAgentflow_0-input-startEphemeralMemory-boolean",
            "display": true
          },
          {
            "label": "Flow State",
            "name": "startState",
            "description": "Runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string",
                "placeholder": "Foo"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "placeholder": "Bar",
                "optional": true
              }
            ],
            "id": "startAgentflow_0-input-startState-array",
            "display": true
          },
          {
            "label": "Persist State",
            "name": "startPersistState",
            "type": "boolean",
            "description": "Persist the state in the same session",
            "optional": true,
            "id": "startAgentflow_0-input-startPersistState-boolean",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "startInputType": "formInput",
          "formTitle": "Research",
          "formDescription": "A research agent that takes in a query, and return a detailed report",
          "formInputTypes": [
            {
              "type": "string",
              "label": "Query",
              "name": "query",
              "addOptions": ""
            }
          ],
          "startEphemeralMemory": "",
          "startState": [
            {
              "key": "subagents",
              "value": ""
            },
            {
              "key": "findings",
              "value": ""
            }
          ],
          "startPersistState": ""
        },
        "outputAnchors": [
          {
            "id": "startAgentflow_0-output-startAgentflow",
            "label": "Start",
            "name": "startAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 102,
      "height": 65,
      "selected": false,
      "positionAbsolute": {
        "x": -179.5,
        "y": 41.5
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_0",
      "position": {
        "x": -21.25,
        "y": 39
      },
      "data": {
        "id": "llmAgentflow_0",
        "label": "Planner",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_0-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_0-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_0-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_0-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>You are a research coordination agent responsible for breaking down a user's query and assigning research tasks to subagents. Your goal is to analyze the query, determine the best research strategy (depth-first, breadth-first, or straightforward), and delegate clear, well-scoped tasks to subagents who will perform the actual research.</p><p>You do <strong>not</strong> generate the final output or report. Your sole responsibility is to create an efficient, well-reasoned plan and deploy the appropriate number of subagents with specific instructions to gather all the information needed to answer the user's question thoroughly and accurately. Use parallel subagents where appropriate, avoid unnecessary overlap, and make sure your instructions are clear, specific, and optimized for quality and efficiency.</p><p>The current date and time is <span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span> .</p>"
            },
            {
              "role": "user",
              "content": "<p>Query:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$form.query\" data-label=\"$form.query\">{{ $form.query }}</span> </p>"
            }
          ],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": [
            {
              "key": "subagents",
              "type": "jsonArray",
              "enumValues": "",
              "jsonSchema": "{\n  \"task\": {\n    \"type\": \"string\",\n    \"description\": \"The research task for subagent\"\n  }\n}",
              "description": "A list of subagents to perform research task"
            }
          ],
          "llmUpdateState": [
            {
              "key": "subagents",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output.subagents\" data-label=\"output.subagents\">{{ output.subagents }}</span> </p>"
            }
          ],
          "llmModelConfig": {
            "cache": "",
            "modelName": "gpt-4o-mini",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoningEffort": "medium",
            "llmModel": "chatOpenAI"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_0-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 174,
      "height": 71,
      "selected": false,
      "positionAbsolute": {
        "x": -21.25,
        "y": 39
      },
      "dragging": false
    },
    {
      "id": "iterationAgentflow_0",
      "position": {
        "x": 204.79536930141506,
        "y": -50.01068378076032
      },
      "data": {
        "id": "iterationAgentflow_0",
        "label": "Iteration 0",
        "version": 1,
        "name": "iterationAgentflow",
        "type": "Iteration",
        "color": "#9C89B8",
        "baseClasses": [
          "Iteration"
        ],
        "category": "Agent Flows",
        "description": "Execute the nodes within the iteration block through N iterations",
        "inputParams": [
          {
            "label": "Array Input",
            "name": "iterationInput",
            "type": "string",
            "description": "The input array to iterate over",
            "acceptVariable": true,
            "rows": 4,
            "id": "iterationAgentflow_0-input-iterationInput-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "iterationInput": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.subagents\" data-label=\"$flow.state.subagents\">{{ $flow.state.subagents }}</span> </p>"
        },
        "outputAnchors": [
          {
            "id": "iterationAgentflow_0-output-iterationAgentflow",
            "label": "Iteration",
            "name": "iterationAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "iteration",
      "width": 300,
      "height": 250,
      "selected": false,
      "positionAbsolute": {
        "x": 204.79536930141506,
        "y": -50.01068378076032
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_0",
      "position": {
        "x": 64.7890461631884,
        "y": 79.4833402176751
      },
      "data": {
        "id": "agentAgentflow_0",
        "label": "Subagent",
        "version": 1,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_0-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_0-input-agentMessages-array",
            "display": true
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_0-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_0-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_0-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_0-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_0-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_0-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatOpenAI",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You're a research subagent assigned a specific task by a research coordinator. Your job is to complete that task efficiently using the available tools (e.g. web search, scraper, Arxiv). Begin by carefully planning your research approach, identifying which tools to use and how many calls you'll need—typically 2–5, with a strict max of 5. Use short, high-signal search queries, prefer high-quality sources, and parallelize tool calls whenever possible.</p><p>As you research, follow an OODA loop: observe what you've learned, orient to what's still needed, decide what to do next, and act. Think critically about source quality—note if content is speculative, biased, or unreliable. Once you have enough information, stop researching and write a clear, fact-rich report with citations. Only include meaningful, necessary citations—no fluff. Your report will be returned to the lead agent to integrate into a final response.</p>"
            }
          ],
          "agentTools": [
            {
              "agentSelectedTool": "arxiv",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "arxivName": "arxiv_search",
                "arxivDescription": "Use this tool to search for academic papers on Arxiv. You can search by keywords, topics, authors, or specific Arxiv IDs. The tool can return either paper summaries or download and extract full paper content.",
                "topKResults": "3",
                "maxQueryLength": "300",
                "docContentCharsMax": "10000",
                "loadFullContent": "",
                "continueOnFailure": "",
                "legacyBuild": "",
                "agentSelectedTool": "arxiv"
              }
            },
            {
              "agentSelectedTool": "tavilyAPI",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "topic": "general",
                "searchDepth": "basic",
                "chunksPerSource": 3,
                "maxResults": 5,
                "timeRange": "",
                "days": 7,
                "includeAnswer": "",
                "includeRawContent": "",
                "includeImages": "",
                "includeImageDescriptions": "",
                "includeDomains": "",
                "excludeDomains": "",
                "agentSelectedTool": "tavilyAPI"
              }
            },
            {
              "agentSelectedTool": "webScraperTool",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "scrapeMode": "recursive",
                "maxDepth": 1,
                "maxPages": 10,
                "timeoutS": 60,
                "description": "",
                "agentSelectedTool": "webScraperTool"
              }
            }
          ],
          "agentKnowledgeDocumentStores": "",
          "agentKnowledgeVSEmbeddings": "",
          "agentEnableMemory": true,
          "agentMemoryType": "allMessages",
          "agentUserMessage": "<p>Research Task:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$iteration\" data-label=\"$iteration\">{{ $iteration }}</span> </p>",
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": "",
          "agentModelConfig": {
            "cache": "",
            "modelName": "gpt-4o-mini",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoningEffort": "medium",
            "agentModel": "chatOpenAI"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_0-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "parentNode": "iterationAgentflow_0",
      "extent": "parent",
      "width": 174,
      "height": 99,
      "selected": false,
      "positionAbsolute": {
        "x": 269.58441546460347,
        "y": 29.47265643691479
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_1",
      "position": {
        "x": 559.1361788991524,
        "y": 38.7953457899211
      },
      "data": {
        "id": "llmAgentflow_1",
        "label": "Writer",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_1-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_1-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_1-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_1-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_1-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_1-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_1-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_1-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>You're an expert research writer tasked with turning raw research findings into a clear, structured, long-form Markdown report. Your job is to retain all relevant information and citations while organizing it into a polished, professional format that fully answers the original user query.</p><p>Start with a compelling title and a 200–300 word abstract, then build out the report with an introduction, thematic sections, a synthesis of insights, implications, and a strong conclusion. Use formal, analytical language and markdown formatting—headings, bullet points, tables—while preserving source integrity and depth. Only output the final Markdown report—no explanations, notes, or commentary.</p>"
            },
            {
              "role": "user",
              "content": "<p>&lt;research_topic&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$form.query\" data-label=\"$form.query\">{{ $form.query }}</span></p><p>&lt;/research_topic&gt;</p><p></p><p>&lt;existing_findings&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.findings\" data-label=\"$flow.state.findings\">{{ $flow.state.findings }}</span> </p><p>&lt;/existing_findings&gt;</p><p></p><p>&lt;new_findings&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"iterationAgentflow_0\" data-label=\"iterationAgentflow_0\">{{ iterationAgentflow_0 }}</span> </p><p>&lt;/new_findings&gt;</p>"
            }
          ],
          "llmEnableMemory": false,
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": [
            {
              "key": "findings",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output\" data-label=\"output\">{{ output }}</span> </p>"
            }
          ],
          "llmModelConfig": {
            "cache": "",
            "modelName": "gpt-4o-mini",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoningEffort": "medium",
            "llmModel": "chatOpenAI"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_1-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 174,
      "height": 71,
      "selected": false,
      "positionAbsolute": {
        "x": 559.1361788991524,
        "y": 38.7953457899211
      },
      "dragging": false
    },
    {
      "id": "conditionAgentAgentflow_0",
      "position": {
        "x": 783.610017823362,
        "y": 35.07935247258487
      },
      "data": {
        "id": "conditionAgentAgentflow_0",
        "label": "More SubAgents?",
        "version": 1.1,
        "name": "conditionAgentAgentflow",
        "type": "ConditionAgent",
        "color": "#ff8fab",
        "baseClasses": [
          "ConditionAgent"
        ],
        "category": "Agent Flows",
        "description": "Utilize an agent to split flows based on dynamic conditions",
        "inputParams": [
          {
            "label": "Model",
            "name": "conditionAgentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Instructions",
            "name": "conditionAgentInstructions",
            "type": "string",
            "description": "A general instructions of what the condition agent should do",
            "rows": 4,
            "acceptVariable": true,
            "placeholder": "Determine if the user is interested in learning about AI",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInstructions-string",
            "display": true
          },
          {
            "label": "Input",
            "name": "conditionAgentInput",
            "type": "string",
            "description": "Input to be used for the condition agent",
            "rows": 4,
            "acceptVariable": true,
            "default": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"question\" data-label=\"question\">{{ question }}</span> </p>",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInput-string",
            "display": true
          },
          {
            "label": "Scenarios",
            "name": "conditionAgentScenarios",
            "description": "Define the scenarios that will be used as the conditions to split the flow",
            "type": "array",
            "array": [
              {
                "label": "Scenario",
                "name": "scenario",
                "type": "string",
                "placeholder": "User is asking for a pizza"
              }
            ],
            "default": [
              {
                "scenario": "More subagents are needed"
              },
              {
                "scenario": "Findings are sufficient"
              }
            ],
            "id": "conditionAgentAgentflow_0-input-conditionAgentScenarios-array",
            "display": true
          },
          {
            "label": "Override System Prompt",
            "name": "conditionAgentOverrideSystemPrompt",
            "type": "boolean",
            "description": "Override initial system prompt for Condition Agent",
            "optional": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentOverrideSystemPrompt-boolean",
            "display": true
          },
          {
            "label": "Node System Prompt",
            "name": "conditionAgentSystemPrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "default": "<p>You are part of a multi-agent system designed to make agent coordination and execution easy. Your task is to analyze the given input and select one matching scenario from a provided set of scenarios.</p>\n    <ul>\n        <li><strong>Input</strong>: A string representing the user's query, message or data.</li>\n        <li><strong>Scenarios</strong>: A list of predefined scenarios that relate to the input.</li>\n        <li><strong>Instruction</strong>: Determine which of the provided scenarios is the best fit for the input.</li>\n    </ul>\n    <h2>Steps</h2>\n    <ol>\n        <li><strong>Read the input string</strong> and the list of scenarios.</li>\n        <li><strong>Analyze the content of the input</strong> to identify its main topic or intention.</li>\n        <li><strong>Compare the input with each scenario</strong>: Evaluate how well the input's topic or intention aligns with each of the provided scenarios and select the one that is the best fit.</li>\n        <li><strong>Output the result</strong>: Return the selected scenario in the specified JSON format.</li>\n    </ol>\n    <h2>Output Format</h2>\n    <p>Output should be a JSON object that names the selected scenario, like this: <code>{\"output\": \"<selected_scenario_name>\"}</code>. No explanation is needed.</p>\n    <h2>Examples</h2>\n    <ol>\n       <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"Hello\", \"scenarios\": [\"user is asking about AI\", \"user is not asking about AI\"], \"instruction\": \"Your task is to check if the user is asking about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is not asking about AI\"}</code></p>\n        </li>\n        <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"What is AIGC?\", \"scenarios\": [\"user is asking about AI\", \"user is asking about the weather\"], \"instruction\": \"Your task is to check and see if the user is asking a topic about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is asking about AI\"}</code></p>\n        </li>\n        <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"Can you explain deep learning?\", \"scenarios\": [\"user is interested in AI topics\", \"user wants to order food\"], \"instruction\": \"Determine if the user is interested in learning about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is interested in AI topics\"}</code></p>\n        </li>\n    </ol>\n    <h2>Note</h2>\n    <ul>\n        <li>Ensure that the input scenarios align well with potential user queries for accurate matching.</li>\n        <li>DO NOT include anything other than the JSON in your response.</li>\n    </ul>",
            "description": "Expert use only. Modifying this can significantly alter agent behavior. Leave default if unsure",
            "show": {
              "conditionAgentOverrideSystemPrompt": true
            },
            "id": "conditionAgentAgentflow_0-input-conditionAgentSystemPrompt-string",
            "display": false
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "conditionAgentModel": "chatOpenAI",
          "conditionAgentInstructions": "<p>Given a research topic, previous subagents and their findings, determine if more subagents are needed for further research or the findings are sufficient for the research topic</p>",
          "conditionAgentInput": "<p>&lt;research_topic&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$form.query\" data-label=\"$form.query\">{{ $form.query }}</span></p><p>&lt;/research_topic&gt;</p><p></p><p>&lt;subagents&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.subagents\" data-label=\"$flow.state.subagents\">{{ $flow.state.subagents }}</span></p><p>&lt;/subagents&gt;</p><p></p><p>&lt;findings&gt;</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.findings\" data-label=\"$flow.state.findings\">{{ $flow.state.findings }}</span></p><p>&lt;/findings&gt;</p>",
          "conditionAgentScenarios": [
            {
              "scenario": "More subagents are needed"
            },
            {
              "scenario": "Findings are sufficient"
            }
          ],
          "conditionAgentOverrideSystemPrompt": "",
          "conditionAgentModelConfig": {
            "cache": "",
            "modelName": "gpt-4o-mini",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoningEffort": "medium",
            "conditionAgentModel": "chatOpenAI"
          }
        },
        "outputAnchors": [
          {
            "id": "conditionAgentAgentflow_0-output-0",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          },
          {
            "id": "conditionAgentAgentflow_0-output-1",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          }
        ],
        "outputs": {
          "conditionAgentAgentflow": ""
        },
        "selected": false
      },
      "type": "agentFlow",
      "width": 186,
      "height": 80,
      "selected": false,
      "positionAbsolute": {
        "x": 783.610017823362,
        "y": 35.07935247258487
      },
      "dragging": false
    },
    {
      "id": "loopAgentflow_0",
      "position": {
        "x": 1034.4868362077264,
        "y": -33.75879891336878
      },
      "data": {
        "id": "loopAgentflow_0",
        "label": "Back to Planner",
        "version": 1,
        "name": "loopAgentflow",
        "type": "Loop",
        "color": "#FFA07A",
        "hideOutput": true,
        "baseClasses": [
          "Loop"
        ],
        "category": "Agent Flows",
        "description": "Loop back to a previous node",
        "inputParams": [
          {
            "label": "Loop Back To",
            "name": "loopBackToNode",
            "type": "asyncOptions",
            "loadMethod": "listPreviousNodes",
            "freeSolo": true,
            "id": "loopAgentflow_0-input-loopBackToNode-asyncOptions",
            "display": true
          },
          {
            "label": "Max Loop Count",
            "name": "maxLoopCount",
            "type": "number",
            "default": 5,
            "id": "loopAgentflow_0-input-maxLoopCount-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "loopBackToNode": "llmAgentflow_0-Planner",
          "maxLoopCount": 5
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 173,
      "height": 65,
      "selected": false,
      "positionAbsolute": {
        "x": 1034.4868362077264,
        "y": -33.75879891336878
      },
      "dragging": false
    },
    {
      "id": "directReplyAgentflow_0",
      "position": {
        "x": 1025.3084160229323,
        "y": 101.62289881234005
      },
      "data": {
        "id": "directReplyAgentflow_0",
        "label": "Generate Report",
        "version": 1,
        "name": "directReplyAgentflow",
        "type": "DirectReply",
        "color": "#4DDBBB",
        "hideOutput": true,
        "baseClasses": [
          "DirectReply"
        ],
        "category": "Agent Flows",
        "description": "Directly reply to the user with a message",
        "inputParams": [
          {
            "label": "Message",
            "name": "directReplyMessage",
            "type": "string",
            "rows": 4,
            "acceptVariable": true,
            "id": "directReplyAgentflow_0-input-directReplyMessage-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "directReplyMessage": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.findings\" data-label=\"$flow.state.findings\">{{ $flow.state.findings }}</span> </p>"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 178,
      "height": 65,
      "selected": false,
      "positionAbsolute": {
        "x": 1025.3084160229323,
        "y": 101.62289881234005
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "startAgentflow_0",
      "sourceHandle": "startAgentflow_0-output-startAgentflow",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#7EE787",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "llmAgentflow_0",
      "sourceHandle": "llmAgentflow_0-output-llmAgentflow",
      "target": "iterationAgentflow_0",
      "targetHandle": "iterationAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#9C89B8",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_0-llmAgentflow_0-output-llmAgentflow-iterationAgentflow_0-iterationAgentflow_0"
    },
    {
      "source": "iterationAgentflow_0",
      "sourceHandle": "iterationAgentflow_0-output-iterationAgentflow",
      "target": "llmAgentflow_1",
      "targetHandle": "llmAgentflow_1",
      "data": {
        "sourceColor": "#9C89B8",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "iterationAgentflow_0-iterationAgentflow_0-output-iterationAgentflow-llmAgentflow_1-llmAgentflow_1"
    },
    {
      "source": "llmAgentflow_1",
      "sourceHandle": "llmAgentflow_1-output-llmAgentflow",
      "target": "conditionAgentAgentflow_0",
      "targetHandle": "conditionAgentAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#ff8fab",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_1-llmAgentflow_1-output-llmAgentflow-conditionAgentAgentflow_0-conditionAgentAgentflow_0"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-0",
      "target": "loopAgentflow_0",
      "targetHandle": "loopAgentflow_0",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#FFA07A",
        "edgeLabel": "0",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-0-loopAgentflow_0-loopAgentflow_0"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-1",
      "target": "directReplyAgentflow_0",
      "targetHandle": "directReplyAgentflow_0",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#4DDBBB",
        "edgeLabel": "1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-1-directReplyAgentflow_0-directReplyAgentflow_0"
    }
  ]
}